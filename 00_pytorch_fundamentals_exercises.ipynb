{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzDBM_v4iMe7"
   },
   "source": [
    "# 00. PyTorch Fundamentals Exercises\n",
    "\n",
    "### 1. Documentation reading \n",
    "\n",
    "A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness):\n",
    "  * The documentation on [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor).\n",
    "  * The documentation on [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGD0oD8Kizak"
   },
   "outputs": [],
   "source": [
    "# No code solution (reading)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__iXqqz-ioUJ"
   },
   "source": [
    "### 2. Create a random tensor with shape `(7, 7)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6pUq9Dc8i2L7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/asyncio/base_events.py\", line 618, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/asyncio/base_events.py\", line 1951, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/xp/xb3qhvl53xb5zr1xf1xrgv0r0000gn/T/ipykernel_25582/152750984.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6553, 0.1061, 0.4962, 0.2341, 0.6843, 0.8914, 0.3320],\n",
      "        [0.3271, 0.8642, 0.7726, 0.1516, 0.6222, 0.0533, 0.1760],\n",
      "        [0.6791, 0.3775, 0.4804, 0.6588, 0.9705, 0.1297, 0.4849],\n",
      "        [0.2486, 0.9689, 0.5630, 0.8373, 0.3339, 0.0668, 0.4963],\n",
      "        [0.1280, 0.2939, 0.6396, 0.6308, 0.5823, 0.7725, 0.3854],\n",
      "        [0.1541, 0.1572, 0.1159, 0.4703, 0.4235, 0.1571, 0.4154],\n",
      "        [0.6794, 0.6559, 0.0740, 0.5305, 0.9595, 0.8376, 0.8373]])\n"
     ]
    }
   ],
   "source": [
    "# Import torch\n",
    "import torch\n",
    "# Create random tensor\n",
    "ten_rand = torch.rand(7,7)\n",
    "print(ten_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/79/78/29dcab24a344ffd9ee9549ec0ab2c7885c13df61cde4c65836ee275efaeb/torch-2.2.2-cp312-none-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading torch-2.2.2-cp312-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Collecting sympy (from torch)\n",
      "  Obtaining dependency information for sympy from https://files.pythonhosted.org/packages/99/ff/c87e0622b1dadea79d2fb0b25ade9ed98954c9033722eb707053d310d4f3/sympy-1.13.3-py3-none-any.whl.metadata\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Obtaining dependency information for jinja2 from https://files.pythonhosted.org/packages/bd/0f/2ba5fbcd631e3e88689309dbe978c5769e883e4b84ebfe7da30b43275c5a/jinja2-3.1.5-py3-none-any.whl.metadata\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: fsspec in /Users/aliyuyusuf/.pyenv/versions/3.12.0/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/22/09/d1f21434c97fc42f09d290cbb6350d44eb12f09cc62c9476effdb33a18aa/MarkupSafe-3.0.2-cp312-cp312-macosx_10_13_universal2.whl.metadata\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-macosx_10_13_universal2.whl.metadata (4.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.2.2-cp312-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.8/150.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0mm\n",
      "\u001b[?25hDownloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-3.0.2-cp312-cp312-macosx_10_13_universal2.whl (14 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, MarkupSafe, jinja2, torch\n",
      "Successfully installed MarkupSafe-3.0.2 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.3 torch-2.2.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-XxvRLfiqkR"
   },
   "source": [
    "### 3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape `(1, 7)` (hint: you may have to transpose the second tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NcLqR0Sbi_vT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.6988],\n",
      "        [1.6278],\n",
      "        [3.0280],\n",
      "        [2.1163],\n",
      "        [1.9967],\n",
      "        [1.8937],\n",
      "        [2.0196]])\n"
     ]
    }
   ],
   "source": [
    "# Create another random tensor\n",
    "tensor1 = torch.rand(7, 7)\n",
    "tensor2 = torch.rand(1, 7)\n",
    "# Perform matrix multiplication, Note: tensor1 @ tensor2 is the most be inthesame diamention to perform matrix multiplication\n",
    "# Therefore, tensor2 has to be transposed.\n",
    "tensor3 = tensor1 @ tensor2.T\n",
    "print(tensor3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiutdKUFiryU"
   },
   "source": [
    "### 4. Set the random seed to `0` and do 2 & 3 over again.\n",
    "\n",
    "The output should be:\n",
    "```\n",
    "(tensor([[1.8542],\n",
    "         [1.9611],\n",
    "         [2.2884],\n",
    "         [3.0481],\n",
    "         [1.7067],\n",
    "         [2.5290],\n",
    "         [1.7989]]), torch.Size([7, 1]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "D-lOWI_1jRMm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8542],\n",
      "        [1.9611],\n",
      "        [2.2884],\n",
      "        [3.0481],\n",
      "        [1.7067],\n",
      "        [2.5290],\n",
      "        [1.7989]])\n",
      "torch.Size([7, 1])\n"
     ]
    }
   ],
   "source": [
    "# Set manual seed\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Create two random tensors\n",
    "tensor_1 = torch.rand(7, 7)\n",
    "tensor_2 = torch.rand(1, 7)\n",
    "tensor_3 = tensor_2.T\n",
    "\n",
    "# Matrix multiply tensors\n",
    "result = torch.matmul(tensor_1, tensor_3)\n",
    "print(result)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezY6ks9Cis37"
   },
   "source": [
    "### 5. Speaking of random seeds, we saw how to set it with `torch.manual_seed()` but is there a GPU equivalent? (hint: you'll need to look into the documentation for `torch.cuda` for this one)\n",
    "  * If there is, set the GPU random seed to `1234`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_LKWcfSTjp00"
   },
   "outputs": [],
   "source": [
    "# Set random seed on the GPU\n",
    "torch.cuda.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ir9qSaj6it4n"
   },
   "source": [
    "\n",
    "### 6. Create two random tensors of shape `(2, 3)` and send them both to the GPU (you'll need access to a GPU for this). Set `torch.manual_seed(1234)` when creating the tensors (this doesn't have to be the GPU random seed). The output should be something like:\n",
    "\n",
    "```\n",
    "Device: cuda\n",
    "(tensor([[0.0290, 0.4019, 0.2598],\n",
    "         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n",
    " tensor([[0.0518, 0.4681, 0.6738],\n",
    "         [0.3315, 0.7837, 0.5631]], device='cuda:0'))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "azXExiFZj5nm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda GPU is not available\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m    \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCuda GPU is not available\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create two random tensors on GPU\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m tensor_1 \u001b[38;5;241m=\u001b[39m \u001b[43mtensor_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m tensor_2 \u001b[38;5;241m=\u001b[39m tensor_2\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     15\u001b[0m tensor_3 \u001b[38;5;241m=\u001b[39m tensor_1 \u001b[38;5;241m+\u001b[39m tensor_2\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/torch/cuda/__init__.py:293\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "torch.cuda.manual_seed(1234)\n",
    "\n",
    "tensor_1 = torch.rand(2, 3)\n",
    "tensor_2 = torch.rand(2, 3)\n",
    "\n",
    "# Check for access to GPU\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA GPU is available')\n",
    "else:\n",
    "   print(\"Cuda GPU is not available\")\n",
    "# Create two random tensors on GPU\n",
    "tensor_1 = tensor_1.cuda()\n",
    "tensor_2 = tensor_2.cuda()\n",
    "tensor_3 = tensor_1 + tensor_2\n",
    "print(tensor_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please not that the error is pop up becouse i use to code the on local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TlAxeiSiu1y"
   },
   "source": [
    "\n",
    "### 7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\n",
    "\n",
    "The output should look like:\n",
    "```\n",
    "(tensor([[0.3647, 0.4709],\n",
    "         [0.5184, 0.5617]], device='cuda:0'), torch.Size([2, 2]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fAeG7ox0lHEO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3937, 0.9461, 0.5871, 1.0260],\n",
      "        [1.4812, 0.4296, 0.7563, 1.0585]])\n"
     ]
    }
   ],
   "source": [
    "# Perform matmul on tensor_A and tensor_B\n",
    "tensor_A = torch.rand(2, 3)\n",
    "tensor_B = torch.rand(3, 4)\n",
    "\n",
    "tensor_C = torch.matmul(tensor_A, tensor_B)\n",
    "print(tensor_C)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7qfa5CSivwg"
   },
   "source": [
    "### 8. Find the maximum and minimum values of the output of 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Fu8_3mZpllOd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4812) tensor(0.4296)\n"
     ]
    }
   ],
   "source": [
    "tensor_C\n",
    "# Find max\n",
    "tensor_C.max()\n",
    "# Find min\n",
    "tensor_C.min()\n",
    "print(tensor_C.max(), tensor_C.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrTj5FgNiw47"
   },
   "source": [
    "### 9. Find the maximum and minimum index values of the output of 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "CCEKt4K2lsfQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4) tensor(5)\n"
     ]
    }
   ],
   "source": [
    "tensor_C\n",
    "# Find arg max\n",
    "tensor_C.argmax()\n",
    "\n",
    "# Find arg min\n",
    "tensor_C.argmin()\n",
    "\n",
    "print(tensor_C.argmax(), tensor_C.argmin())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmeybz4uixy7"
   },
   "source": [
    "\n",
    "### 10. Make a random tensor with shape `(1, 1, 1, 10)` and then create a new tensor with all the `1` dimensions removed to be left with a tensor of shape `(10)`. Set the seed to `7` when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\n",
    "\n",
    "The output should look like:\n",
    "\n",
    "```\n",
    "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
    "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
    "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
    "        0.8513]) torch.Size([10])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TQ9zbRzVl1jV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
      "        0.8513])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(7)\n",
    "\n",
    "# Create random tensor\n",
    "tensor = torch.rand(1, 1, 1, 10)\n",
    "# Remove single dimensions\n",
    "remove_tensor = torch.squeeze(tensor)\n",
    "\n",
    "# Print out tensors and their shapes\n",
    "print(remove_tensor)\n",
    "print(remove_tensor.shape)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "00_pytorch_fundamentals_exercises.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
